# -*- coding: utf-8 -*-
"""Space X Falcon 9 First Stage Landing Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KPZEIf_0YSkJJK-EjL9hW30rQ99_Czgn

**Objectives**

Web scrap Falcon 9 launch records with BeautifulSoup:

Extract a Falcon 9 launch records HTML table from Wikipedia
Parse the table and convert it into a Pandas data frame
"""

!pip install beautifulsoup4
!pip install requests

import sys

#Gives access to system-specific parameters and functions.

#Useful for reading command-line arguments (sys.argv), exiting (sys.exit()), or checking Python version.
import requests
from bs4 import BeautifulSoup
import re       #Useful for pattern matching, cleaning, or extracting text.
import unicodedata   #Handles Unicode characters.Useful for cleaning text (removing accents, normalizing).
import pandas as pd

"""and we will provide some helper functions for you to process web scraped HTML table"""

def date_time(table_cells):
  #This function returns the data and time from the HTML  table cell
   # Input: the  element of a table data cell extracts extra row
  return [date_time.strip() for date_time in list(table_cells.string)][0:2]

def booster_version(table_cells):
  out = ''.join([booster_version for i,booster_version in enumerate(table_cells.string) if i%2==0][0:-1])
  return out

def get_mass(table_cells):
  mass = unicodedata.normalize('NFKD', table_cells.text).strip()
  if mass:
    mass.find('kg')
    new_mass = mass[0:mass.find('kg')+2]
  else:
    new_mass = 0
  return mass

def extract_column_from_header(row):
  if row.br:
    row.br.extract()
  if row.a:
    row.a.extract()
  if row.sup:
    row.sup.extract()

  column_name = ''.join(row.contents)
  if not(column_name.strip().isdigit()):
    column_name = column_name.strip()
    return column_name

static_url = "https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922"

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/91.0.4472.124 Safari/537.36"
}

"""**TASK 1: Request the Falcon9 Launch Wiki page from its URL**"""

response = requests.get(static_url,headers = headers)

if response.status_code == 200:
  soup = BeautifulSoup(response.text,'html.parser')
  print('Page title:', soup.title.string)
else:
  print('Failed to retrieve page:', response.status_code)

print(soup.title.attribute)

"""**TASK 2: Extract all column/variable names from the HTML table header**

Next, we want to collect all relevant column names from the HTML table header

Let's try to find all tables on the wiki page first. If you need to refresh your memory about BeautifulSoup, please check the external reference link towards the end of this lab
"""

html_tables = soup.find_all('table')

"""Starting from the third table is our target table contains the actual launch records."""

first_launch_table = html_tables[2]
first_launch_table

"""Next, we just need to iterate through the <th> elements and apply the provided extract_column_from_header() to extract column name one by one"""

column_names = []

first_launch_table_th = first_launch_table.find_all('th')

for th in first_launch_table_th:
  column_name = extract_column_from_header(th)
  if column_name is not None and len(column_name) > 0:
    column_names.append(column_name)

print(column_names)

"""**TASK 3: Create a data frame by parsing the launch HTML tables**

We will create an empty dictionary with keys from the extracted column names in the previous task. Later, this dictionary will be converted into a Pandas dataframe
"""

launch_dict = dict.fromkeys(column_names)

del launch_dict['Date andtime ()']

launch_dict['Flight No.'] = []
launch_dict['Launch site'] = []
launch_dict['Payload'] = []
launch_dict['Payload mass'] = []
launch_dict['Orbit'] = []
launch_dict['Customer'] = []
launch_dict['Launchoutcome'] = []
launch_dict['Version Booster'] = []
launch_dict['Booster Landing'] = []
launch_dict['Date'] = []
launch_dict['Time'] = []

"""Next, we just need to fill up the launch_dict with launch records extracted from table rows.

Usually, HTML tables in Wiki pages are likely to contain unexpected annotations and other types of noises, such as reference links B0004.1[8], missing values N/A [e], inconsistent formatting, etc.

To simplify the parsing process, we have provided an incomplete code snippet below to help you to fill up the launch_dict. Please complete the following code snippet with TODOs or you can choose to write your own logic to parse all launch tables:
"""

extracted_row = 0
#Extract each table
for table_number,table in enumerate(soup.find_all('table','wikitable plainrowheaders collapsible')):
  for rows in table.find_all('tr'):
    if rows.th:
      if rows.th.string:
        flight_number = rows.th.string.strip()
        flag = flight_number.isdigit()
    else:
      flag = False
      rows = rows.find_all('td')
      if flag:
        extracted_row += 1
        flight_number.append(launch_dict['Flight No.'])
        print(flight_number)
        datetimelist = date_time(rows[0])
        date.append(launch_dict['Date'])
        date = datetimelist[0].strip(',')
        print(date)
        time.append(launch_dict['Time'])
        time = datetimelist[1]
        print(time)
        bv.append(launch_dict['Version Booster'])
        bv = booster_version(rows[1])
        if not(bv):
          bv = rows[1].a.string
        print(bv)
        launch_site.append(launch_dict['Launch site'])
        launch_site = rows[2].a.string
        print(launch_site)
        payload.append(launch_dict['Payload'])
        payload = rows[3].a.string
        print(payload)
        payload_mass.append(launch_dict['Payload mass'])
        payload_mass = get_mass(rows[4])
        print(payload_mass)
        orbit.append(launch_dict['Orbit'])
        orbit = rows[5].a.string
        print(orbit)
        customer.append(launch_dict['Customer'])
        customer = rows[6].a.string
        print(customer)
        launch_outcome.append(launch_dict['Launchoutcome'])
        launch_outcome = list(rows[7].strings)[0]
        print(launch_outcome)
        booster_landing.append(launch_dict['Booster Landing'])
        booster_landing = landing_status(rows[8])
        print(booster_landing)

"""After you have fill in the parsed launch record values into launch_dict, you can create a dataframe from it."""

df = pd.DataFrame({ key:pd.Series(value) for key, value in launch_dict.items() })

df.to_csv('spacex_web_scraped.csv', index=False)

from google.colab import files
files.download('spacex_web_scraped.csv')